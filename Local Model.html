<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
	<meta name="description" content="" />
	<meta name="author" content="" />
	<title>Testing and Debugging Machine Learning Models</title>
	<!-- Font Awesome icons (free version)-->
	<script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
	
	<!-- Google fonts-->
	https://github.com/krishnakhadka200416/TestingAndDebuggingMLModels

	<link href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900" rel="stylesheet" />
	<link href="https://fonts.googleapis.com/css?family=Lato:100,100i,300,300i,400,400i,700,700i,900,900i" rel="stylesheet" />
	<!-- Core theme CSS (includes Bootstrap)-->
	<link href="styles.css" rel="stylesheet" />
	<style>
		a:link {
		  color: blue;
		  background-color: transparent;
		  text-decoration: none;
		}
		a:visited {
			color: rgb(8, 57, 170);
			background-color: transparent;
			text-decoration: none;
		}
		</style>
</head>

<body id="page-top">
	<section>

		<nav class="navbar navbar-expand-lg navbar-dark navbar-custom fixed-top"  style="background-color: black;">
			<div class="container px-5">
				<a class="navbar-brand" href="#page-top">Testing & Debugging ML Models</a>
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
				<div class="collapse navbar-collapse" id="navbarResponsive">
					<ul class="navbar-nav ms-auto">
                        <li class="nav-item"><a class="nav-link" href="#about">ABOUT</a></li>
                        <li class="nav-item"><a class="nav-link" href="./Related Papers.html">Papers</a></li>
                        <li class="nav-item"><a class="nav-link" href="./Local Model.html">Local Models</a></li>
                        <li class="nav-item"><a class="nav-link" href="./Software_Tools.html">Software Tools</a></li>
                        <li class="nav-item"><a class="nav-link" href="./Connect.html">CONNECT</a></li>
					</ul>
				</div>
			</div>
		</nav>
	</section>
<section id = "resources">
    <div class="container px-5">
		<div class="row gx-5 align-items-center">
			<div class="row d-flex justify-content-center mt-100 mb-100">

				<h1 style="margin-top: 20"><b><center><b>Local Model Building</b></center></b></h1>


				<h3 style="margin-top: 20px"><b> Introduction: </b></h3>
        <p>
          Most machine learning models are complex black box predictions which can be hard to trust. 
                     
          One way to build trust is by building a local interpretable model around the instance of interest.
          
          <br>
          This web page consists of papers that use local models to interpret the predictions. 

        </p>

				<h5 style="margin-top: 20px"><b> Key Words</b></h5>
				<ol>
					<li>
						Local Model
					</li>
					<li>
						Debugging Machine Learning Model
					</li>
					<li>
						Neighborhood machine learning
					</li>
				</ol>
				<h5 style="margin-top: 20px"><b>Research Papers:</b></h5>
				<style type="text/css">
					.tg  {border-collapse:collapse;border-spacing:0;}
					.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
					  overflow:hidden;padding:10px 5px;word-break:normal;}
					.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
					  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
					.tg .tg-0lax{text-align:left;vertical-align:top}
				</style>

<table class="tg">
				
    <thead>
        <tr>
          <th class="tg-0lax">Title</th>
          <th class="tg-0lax">Authors </th>
          <th class="tg-0lax">Venues/Conference/Journal</th>
          <th class="tg-0lax">Year</th>
          <th class="tg-0lax">Page#</th>
        </tr>
    </thead> 

    <tbody>
        
            <tr>
            <td class="tg-0lax"><a href="https://arxiv.org/pdf/1602.04938.pdf?source=post_page---------------------------" target="_blank">" Why should i trust you?" Explaining the predictions of any classifier </a></td>
            <td class="tg-0lax">Ribeiro, M. T., Singh, S., & Guestrin</td>
            <td class="tg-0lax">international conference on knowledge discovery and data mining.</td>
            <td class="tg-0lax">2016</td>
            <td class="tg-0lax">1135-1144</td>
            </tr>

            <tr>
                <td class="tg-0lax"><a href="https://arxiv.org/pdf/2001.06216.pdf" target="_blank">Graphlime: Local interpretable model explanations for graph neural networks</a></td>
                <td class="tg-0lax">Huang, Q., Yamada, M., Tian, Y., Singh, D., & Chang, Y.</td>
                <td class="tg-0lax">IEEE Transactions on Knowledge and Data Engineering </td>
                <td class="tg-0lax">2022</td>
                <td class="tg-0lax">N/A</td>
              </tr>
            
            <tr>
                <td class="tg-0lax"><a href="https://arxiv.org/pdf/2002.07434.pdf" target="_blank">A modified perturbed sampling method for local interpretable model-agnostic explanation</a></td>
                <td class="tg-0lax">Shi, S., Zhang, X., & Fan, W. </td>
                <td class="tg-0lax">N/A</td>
                <td class="tg-0lax">2020</td>
                <td class="tg-0lax">1135-1144</td>
            </tr>
            
            <tr>
              <td class="tg-0lax"><a href="http://proceedings.mlr.press/v108/garreau20a/garreau20a.pdf" target="_blank">Explaining the Explainer: A First Theoretical Analysis of LIME</a></td>
              <td class="tg-0lax">Garreau, D., & Luxburg, U. </td>
              <td class="tg-0lax">International Conference on Artificial Intelligence and Statistics</td>
              <td class="tg-0lax">2020</td>
              <td class="tg-0lax">1287-1296</td>
          </tr>

            
          <tr>
            <td class="tg-0lax"><a href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467274" target="_blank">S-LIME: Stabilized-LIME for Model Explanation</a></td>
            <td class="tg-0lax">Zhou, Z., Hooker, G., & Wang, F.  </td>
            <td class="tg-0lax">ACM SIGKDD conference on knowledge discovery & data mining </td>
            <td class="tg-0lax">2021</td>
            <td class="tg-0lax">2429-2438</td>
        </tr>
        
          
           


          

            <tr>
                <td class="tg-0lax"><a href="https://ieeexplore.ieee.org/abstract/document/9338395" target="_blank">Data-agnostic local neighborhood generation</a></td>
                <td class="tg-0lax">Guidotti, R., & Monreale, A.  </td>
                <td class="tg-0lax">IEEE International Conference on Data Mining </td>
                <td class="tg-0lax">2020</td>
                <td class="tg-0lax">1040-1050</td>
            </tr>

            
           

        

          <tr>
            <td class="tg-0lax"><a href="https://dl.acm.org/doi/pdf/10.1145/3375627.3375830" target="_blank">Fooling lime and shap: Adversarial attacks on post hoc explanation methods</a></td>
            <td class="tg-0lax">Slack, D., Hilgard, S., Jia, E., Singh, S., & Lakkaraju, H. </td>
            <td class="tg-0lax">AAAI/ACM Conference on AI, Ethics, and Society</td>
            <td class="tg-0lax">2020</td>
            <td class="tg-0lax">180-186</td>
          </tr>
          <tr>
            <td class="tg-0lax"><a href="https://arxiv.org/pdf/1909.02437.pdf" target="_blank">ALIME: Autoencoder based approach for local interpretability</a></td>
            <td class="tg-0lax">Shankaranarayana, S. M., & Runje, D.</td>
            <td class="tg-0lax">International conference on intelligent data engineering and automated learning</td>
            <td class="tg-0lax">2019</td>
            <td class="tg-0lax">454-463</td>
        </tr>

          <tr>
            <td class="tg-0lax"><a href="https://arxiv.org/pdf/1707.01154.pdf" target="_blank">Measurable counterfactual local explanations for any classifier</a></td>
            <td class="tg-0lax">White, A., & Garcez, A. D. A.</td>
            <td class="tg-0lax">arxiv </td>
            <td class="tg-0lax">2019</td>
            <td class="tg-0lax">N/A</td>
          </tr>

          <tr>
            <td class="tg-0lax"><a href="https://arxiv.org/pdf/1911.01058.pdf" target="_blank">Explaining the predictions of any image classifier via decision trees</a></td>
            <td class="tg-0lax">Shi, S., Zhang, X., & Fan, W.</td>
            <td class="tg-0lax">AAAI conference on artificial intelligence</td>
            <td class="tg-0lax">2019</td>
            <td class="tg-0lax">N/A</td>
          </tr>

        

          <tr>
            <td class="tg-0lax"><a href="https://proceedings.neurips.cc/paper/2018/file/b495ce63ede0f4efc9eec62cb947c162-Paper.pdf" target="_blank">Model agnostic supervised local explanations</a></td>
            <td class="tg-0lax">Plumb, Gregory, Denali Molitor, and Ameet S. Talwalkar.</td>
            <td class="tg-0lax"> Neural Information Processing Systems </td>
            <td class="tg-0lax">2018</td>
            <td class="tg-0lax">N/A</td>
          </tr>
          <tr>
            <td class="tg-0lax"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/11491" target="_blank">Anchors: High-precision model-agnostic explanations</a></td>
            <td class="tg-0lax">Ribeiro, M. T., Singh, S., & Guestrin, C. </td>
            <td class="tg-0lax">AAAI conference on artificial intelligence</td>
            <td class="tg-0lax">2018</td>
            <td class="tg-0lax">N/A</td>
        </tr>
          <tr>
            <td class="tg-0lax"><a href="http://proceedings.mlr.press/v80/chen18j/chen18j.pdf" target="_blank">Learning to explain: An information-theoretic perspective on model interpretation</a></td>
            <td class="tg-0lax">Chen, J., Song, L., Wainwright, M., & Jordan, M. </td>
            <td class="tg-0lax">International Conference on Machine Learning </td>
            <td class="tg-0lax">2018</td>
            <td class="tg-0lax">883-892</td>
          </tr>
          <tr>
            <td class="tg-0lax"><a href="http://artifacts.h2o.ai.s3.amazonaws.com/releases/ai/h2o/dai/rel-1.6.1-12/docs/booklets/MLIBooklet.pdf" target="_blank">Machine Learning Interpretability
                with H2O Driverless AI</a></td>
            <td class="tg-0lax">Hall, P., Gill, N., Kurka, M., & Phan, W.</td>
            <td class="tg-0lax">N/A </td>
            <td class="tg-0lax">2017</td>
            <td class="tg-0lax">1-40</td>
          </tr>



          <tr>
            <td class="tg-0lax"><a href="https://arxiv.org/pdf/1707.01154.pdf" target="_blank">Interpretable & explorable approximations of black box models</a></td>
            <td class="tg-0lax">Lakkaraju, H., Kamar, E., Caruana, R., & Leskovec, J. </td>
            <td class="tg-0lax">arxiv </td>
            <td class="tg-0lax">2017</td>
            <td class="tg-0lax">N/A</td>
          </tr>

                
            
         

            
        

    </tbody>
</table>

			


				
				
										
			
				
			</div>
		</div>
	</div>
</section>


</body>
</html>
